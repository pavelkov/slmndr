import torch
#################################### For Image ####################################
from PIL import Image
from sam3.model_builder import build_sam3_image_model
from sam3.model.sam3_image_processor import Sam3Processor
# Load the model
model = build_sam3_image_model(checkpoint_path='/data/Env/Dev/T/sam3.pt')
processor = Sam3Processor(model)


import numpy as np
import matplotlib

def overlay_masks(image, masks):
    image = image.convert("RGBA")
    masks = 255 * masks.cpu().numpy().astype(np.uint8)
    
    n_masks = masks.shape[0]
    cmap = matplotlib.colormaps.get_cmap("rainbow").resampled(n_masks)
    colors = [
        tuple(int(c * 255) for c in cmap(i)[:3])
        for i in range(n_masks)
    ]
    color = colors[0]
    #for mask, color in zip(masks, colors):
    for mask in masks:
        mask = Image.fromarray(mask.squeeze())
        overlay = Image.new("RGBA", image.size, color + (0,))
        alpha = mask.point(lambda v: int(v * 0.5))
        overlay.putalpha(alpha)
        image = Image.alpha_composite(image, overlay)
    return image


image = Image.open("/home/hobo/Dropbox/Dev/Slmndr/Data/ImagesGood/Screenshot_20240505_203021_Gallery.jpg")
inference_state = processor.set_image(image)
# Prompt the model with text
output = processor.set_text_prompt(state=inference_state, prompt="salamandra")

# Get the masks, bounding boxes, and scores
masks, boxes, scores = output["masks"], output["boxes"], output["scores"]


mask = masks[0]
bbox = boxes[0]


import numpy as np
import cv2

img_np = np.array(image)   # (H, W, 3)

# mask: torch tensor
# shapes accepted: (H, W), (1, H, W), (H, W, 1)
mask = mask.squeeze() > 0   # boolean (H, W)

# apply mask
img_np[~mask.cpu().numpy()] = 0

# back to PIL
result = Image.fromarray(img_np)

x1, y1, x2, y2 = bbox.round().int().tolist()

cropped = result.crop((x1, y1, x2, y2))


inference_state = processor.set_image(cropped)
# Prompt the model with text
output = processor.set_text_prompt(state=inference_state, prompt="tail")

# Get the masks, bounding boxes, and scores
masks, boxes, scores = output["masks"], output["boxes"], output["scores"]


overlay_masks(cropped, masks)



